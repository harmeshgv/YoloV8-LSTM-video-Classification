{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory(directory_path, file_extenion = None):\n",
    "    try:\n",
    "        all_files = os.listdir(directory_path)\n",
    "        \n",
    "        if file_extenion:\n",
    "            files = [f for f in all_files if f.endswith(file_extenion)]\n",
    "            \n",
    "        else:\n",
    "            files = all_files\n",
    "            \n",
    "        return files\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The directory {directory_path} does not exist\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwf_train_non_violence_video_path =  \"video_data/RWF-2000/train/NonFight\"\n",
    "rwf_train_violence_video_path = \"video_data/RWF-2000/train/Fight\"\n",
    "rwf_val_non_violence_video_path = \"video_data/RWF-2000/val/NonFight\"\n",
    "rwf_val_violence_video_path = \"video_data/RWF-2000/val/Fight\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwf_train_non_violence_video_files = list_files_in_directory(rwf_train_non_violence_video_path)\n",
    "rwf_train_violence_video_files = list_files_in_directory(rwf_train_violence_video_path)\n",
    "rwf_val_non_violence_video_files = list_files_in_directory(rwf_val_non_violence_video_path)\n",
    "rwf_val_violence_video_files = list_files_in_directory(rwf_val_violence_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 789 200 800\n"
     ]
    }
   ],
   "source": [
    "print(len(rwf_val_violence_video_files),\n",
    "len(rwf_train_violence_video_files),\n",
    "len(rwf_val_non_violence_video_files),\n",
    "len(rwf_train_non_violence_video_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwf_val_non_violence_video_files = rwf_val_non_violence_video_files[104:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96/96 [10:26<00:00,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ZwhC7Kyg_0.avi: 485 interactions saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from backend.utils.feature_extraction import ViolenceFeatureExtractor\n",
    "from backend.utils.data_preprocessing import preprocess_data\n",
    "\n",
    "# Absolute paths to your models\n",
    "detection_model_path = \"backend/models/yolo8n.pt\"\n",
    "pose_model_path = \"backend/models/yolo8n.pt\"\n",
    "\n",
    "# Check if the model files exist\n",
    "if not os.path.exists(detection_model_path):\n",
    "    raise FileNotFoundError(f\"Detection model not found at {detection_model_path}\")\n",
    "\n",
    "if not os.path.exists(pose_model_path):\n",
    "    raise FileNotFoundError(f\"Pose model not found at {pose_model_path}\")\n",
    "\n",
    "# Initialize the feature extractor\n",
    "extractor = ViolenceFeatureExtractor()\n",
    "\n",
    "# Path to the final CSV where data will be appended\n",
    "final_csv_path = 'extracted_feature_data/val_non_violence_data.csv'\n",
    "\n",
    "# Path to save the output CSV\n",
    "output_csv_path = 'extracted_feature_data/sample.csv'\n",
    "\n",
    "full_log = []\n",
    "\n",
    "# tqdm loop with description\n",
    "for video_name in tqdm(rwf_val_non_violence_video_files, desc=\"Processing Videos\"):\n",
    "    try:\n",
    "        extractor.reset()\n",
    "        video_path = os.path.join(rwf_val_non_violence_video_path, video_name)\n",
    "\n",
    "        print(f\"\\nüìπ Processing video: {video_name}\")\n",
    "        frame_width, frame_height, interaction_count = extractor.process_video(\n",
    "            video_path,\n",
    "            output_csv_path,\n",
    "            output_folder=None,\n",
    "            show_video=False,\n",
    "            save_video=False\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        df_csv = pd.read_csv(output_csv_path)\n",
    "        df_preprocessed, expected_columns = preprocess_data(df_csv, frame_width, frame_height)\n",
    "\n",
    "        # Skip appending if there are no interactions (empty dataframe)\n",
    "        if df_preprocessed.empty:\n",
    "            log_entry = f\"‚ùå {video_name}: No interactions found\"\n",
    "            print(log_entry)\n",
    "            full_log.append(log_entry)\n",
    "            continue  # Skip to the next video\n",
    "\n",
    "        # Check if the final CSV exists and has data\n",
    "        if os.path.exists(final_csv_path) and os.path.getsize(final_csv_path) > 0:\n",
    "            # Append to the existing CSV\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Create a new CSV with the appropriate header\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='w', header=True, index=False)\n",
    "\n",
    "        log_entry = f\"‚úÖ {video_name}: {len(df_preprocessed)} interactions saved\"\n",
    "        print(log_entry)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_entry = f\"‚ùå Error processing {video_name}: {e}\"\n",
    "        print(log_entry)\n",
    "\n",
    "    full_log.append(log_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [22:40<00:00,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ zOqs7Oh9oDM_3.avi: 14 interactions saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from backend.utils.feature_extraction import ViolenceFeatureExtractor\n",
    "from backend.utils.data_preprocessing import preprocess_data\n",
    "\n",
    "# Absolute paths to your models\n",
    "detection_model_path = \"backend/models/yolo8n.pt\"\n",
    "pose_model_path = \"backend/models/yolo8n.pt\"\n",
    "\n",
    "# Check if the model files exist\n",
    "if not os.path.exists(detection_model_path):\n",
    "    raise FileNotFoundError(f\"Detection model not found at {detection_model_path}\")\n",
    "\n",
    "if not os.path.exists(pose_model_path):\n",
    "    raise FileNotFoundError(f\"Pose model not found at {pose_model_path}\")\n",
    "\n",
    "# Initialize the feature extractor\n",
    "extractor = ViolenceFeatureExtractor()\n",
    "\n",
    "# Path to the final CSV where data will be appended\n",
    "final_csv_path = 'extracted_feature_data/val_violence_data.csv'\n",
    "\n",
    "# Path to save the output CSV\n",
    "output_csv_path = 'extracted_feature_data/sample.csv'\n",
    "\n",
    "full_log = []\n",
    "\n",
    "# tqdm loop with description\n",
    "for video_name in tqdm(rwf_val_violence_video_files, desc=\"Processing Videos\"):\n",
    "    try:\n",
    "        extractor.reset()\n",
    "        video_path = os.path.join(rwf_val_violence_video_path, video_name)\n",
    "\n",
    "        print(f\"\\nüìπ Processing video: {video_name}\")\n",
    "        frame_width, frame_height, interaction_count = extractor.process_video(\n",
    "            video_path,\n",
    "            output_csv_path,\n",
    "            output_folder=None,\n",
    "            show_video=False,\n",
    "            save_video=False\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        df_csv = pd.read_csv(output_csv_path)\n",
    "        df_preprocessed, expected_columns = preprocess_data(df_csv, frame_width, frame_height)\n",
    "\n",
    "        # Skip appending if there are no interactions (empty dataframe)\n",
    "        if df_preprocessed.empty:\n",
    "            log_entry = f\"‚ùå {video_name}: No interactions found\"\n",
    "            print(log_entry)\n",
    "            full_log.append(log_entry)\n",
    "            continue  # Skip to the next video\n",
    "\n",
    "        # Check if the final CSV exists and has data\n",
    "        if os.path.exists(final_csv_path) and os.path.getsize(final_csv_path) > 0:\n",
    "            # Append to the existing CSV\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Create a new CSV with the appropriate header\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='w', header=True, index=False)\n",
    "\n",
    "        log_entry = f\"‚úÖ {video_name}: {len(df_preprocessed)} interactions saved\"\n",
    "        print(log_entry)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_entry = f\"‚ùå Error processing {video_name}: {e}\"\n",
    "        print(log_entry)\n",
    "\n",
    "    full_log.append(log_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwf_train_violence_video_files = rwf_train_violence_video_files[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rProcessing Videos:   2%|‚ñè         | 16/753 [01:42<1:08:56,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 3kpviz7lAMY_0.avi: 4 interactions saved\n",
      "\n",
      "üìπ Processing video: 3kpviz7lAMY_1.avi\n",
      "Input resolution: 428x240\n",
      "Frame skip: 1\n",
      "Batch size: 1\n",
      "Processing video: 428x240 at 30.0 fps\n",
      "Using frame_skip: 1, batch_size: 1\n",
      "Processing frame 0/150 (0.0%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 1/150 (0.7%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 2/150 (1.3%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 3/150 (2.0%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 4/150 (2.7%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 5/150 (3.3%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 6/150 (4.0%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 7/150 (4.7%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 8/150 (5.3%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 9/150 (6.0%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n",
      "Processing frame 10/150 (6.7%)Original size: 428x240, Resized size: 640x358\n",
      "Padding: (pad_w: 0, pad_h: 141)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from backend.utils.feature_extraction import ViolenceFeatureExtractor\n",
    "from backend.utils.data_preprocessing import preprocess_data\n",
    "\n",
    "# Absolute paths to your models\n",
    "detection_model_path = \"backend/models/yolo8n.pt\"\n",
    "pose_model_path = \"backend/models/yolo8n.pt\"\n",
    "\n",
    "# Check if the model files exist\n",
    "if not os.path.exists(detection_model_path):\n",
    "    raise FileNotFoundError(f\"Detection model not found at {detection_model_path}\")\n",
    "\n",
    "if not os.path.exists(pose_model_path):\n",
    "    raise FileNotFoundError(f\"Pose model not found at {pose_model_path}\")\n",
    "\n",
    "# Initialize the feature extractor\n",
    "extractor = ViolenceFeatureExtractor()\n",
    "\n",
    "# Path to the final CSV where data will be appended\n",
    "final_csv_path = 'extracted_feature_data/train_violence_data.csv'\n",
    "\n",
    "# Path to save the output CSV\n",
    "output_csv_path = 'extracted_feature_data/sample.csv'\n",
    "\n",
    "full_log = []\n",
    "\n",
    "# tqdm loop with description\n",
    "for video_name in tqdm(rwf_train_violence_video_files, desc=\"Processing Videos\"):\n",
    "    try:\n",
    "        extractor.reset()\n",
    "        video_path = os.path.join(rwf_train_violence_video_path, video_name)\n",
    "\n",
    "        print(f\"\\nüìπ Processing video: {video_name}\")\n",
    "        frame_width, frame_height, interaction_count = extractor.process_video(\n",
    "            video_path,\n",
    "            output_csv_path,\n",
    "            output_folder=None,\n",
    "            show_video=False,\n",
    "            save_video=False\n",
    "        )\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        df_csv = pd.read_csv(output_csv_path)\n",
    "        df_preprocessed, expected_columns = preprocess_data(df_csv, frame_width, frame_height)\n",
    "\n",
    "        # Skip appending if there are no interactions (empty dataframe)\n",
    "        if df_preprocessed.empty:\n",
    "            log_entry = f\"‚ùå {video_name}: No interactions found\"\n",
    "            print(log_entry)\n",
    "            full_log.append(log_entry)\n",
    "            continue  # Skip to the next video\n",
    "\n",
    "        # Check if the final CSV exists and has data\n",
    "        if os.path.exists(final_csv_path) and os.path.getsize(final_csv_path) > 0:\n",
    "            # Append to the existing CSV\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            # Create a new CSV with the appropriate header\n",
    "            df_preprocessed.to_csv(final_csv_path, mode='w', header=True, index=False)\n",
    "\n",
    "        log_entry = f\"‚úÖ {video_name}: {len(df_preprocessed)} interactions saved\"\n",
    "        print(log_entry)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_entry = f\"‚ùå Error processing {video_name}: {e}\"\n",
    "        print(log_entry)\n",
    "\n",
    "    full_log.append(log_entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataset_download() got an unexpected keyword argument 'progress'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvideo_data\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvideo_data_downloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m download_dataset\n\u001b[1;32m----> 3\u001b[0m download_dpath \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\harme\\Desktop\\YoloV8-LSTM-video-Classification\\video_data\\video_data_downloader.py:5\u001b[0m, in \u001b[0;36mdownload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_dataset\u001b[39m():\n\u001b[1;32m----> 5\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvulamnguyen/rwf2000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[1;31mTypeError\u001b[0m: dataset_download() got an unexpected keyword argument 'progress'"
     ]
    }
   ],
   "source": [
    "from video_data.video_data_downloader import download_dataset\n",
    "\n",
    "download_dpath = download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
